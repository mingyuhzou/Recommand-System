{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:06.925033Z",
     "start_time": "2025-10-25T09:30:06.911702Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.369602Z",
     "start_time": "2025-10-25T09:30:06.939614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data=torchvision.datasets.CIFAR10(root='./datasets',train=True,download=True,transform=transforms.ToTensor())\n",
    "test_data=torchvision.datasets.CIFAR10(root='./datasets',train=False,download=True,transform=transforms.ToTensor())"
   ],
   "id": "567aae98176e1d19",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.394544Z",
     "start_time": "2025-10-25T09:30:09.378925Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_data),len(test_data)",
   "id": "529b9b36e97da9f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.425742Z",
     "start_time": "2025-10-25T09:30:09.410050Z"
    }
   },
   "cell_type": "code",
   "source": "device=torch.device('cpu' if not torch.cuda.is_available() else 'cuda')",
   "id": "66ba718cb274bd30",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.473511Z",
     "start_time": "2025-10-25T09:30:09.463614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=nn.Sequential(\n",
    "        nn.Conv2d(3,32,5,padding=2),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32,32,5,padding=2),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32,64,5,padding=2),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(1024,64),\n",
    "        nn.Linear(64,10))\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ],
   "id": "6e97f1d6e7e070fa",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.497413Z",
     "start_time": "2025-10-25T09:30:09.483975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_loader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_data_loader=DataLoader(test_data,batch_size=64,shuffle=True)"
   ],
   "id": "49e4ac5b375ff9ab",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.639467Z",
     "start_time": "2025-10-25T09:30:09.503541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model=myModel()\n",
    "model.to(device)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "learning_rate=1e-2\n",
    "epoch=10\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ],
   "id": "3ec822e9d10651a2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.655532Z",
     "start_time": "2025-10-25T09:30:09.643617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_train_times=0\n",
    "total_test_times=0"
   ],
   "id": "52f0bf99055065ed",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:30:09.677418Z",
     "start_time": "2025-10-25T09:30:09.663820Z"
    }
   },
   "cell_type": "code",
   "source": "writer=SummaryWriter('log8')",
   "id": "742ae2f83b6e181d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:32:47.300407Z",
     "start_time": "2025-10-25T09:30:09.683700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1,epoch+1):\n",
    "    print(f'-------------epoch:{i} begining---------------')\n",
    "    for data in train_data_loader:\n",
    "        imgs,labels=data\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(imgs)\n",
    "        loss=loss_fn(outputs,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_times+=1\n",
    "        if total_train_times%100==0:\n",
    "            print('total_train_times:',total_train_times,'total_loss:',loss)\n",
    "    total_loss=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            imgs,labels=data\n",
    "            imgs=imgs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs=model(imgs)\n",
    "            loss=loss_fn(outputs,labels)\n",
    "            total_loss+=loss\n",
    "    total_test_times+=1\n",
    "    print('total_loss:',total_loss)\n",
    "    writer.add_scalar('test_loss',total_loss,total_train_times)"
   ],
   "id": "1a3897882ddc2303",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------epoch:1 begining---------------\n",
      "total_train_times: 100 total_loss: tensor(2.2922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 200 total_loss: tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 300 total_loss: tensor(2.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 400 total_loss: tensor(2.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 500 total_loss: tensor(2.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 600 total_loss: tensor(1.9521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 700 total_loss: tensor(2.2426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(303.5390, device='cuda:0')\n",
      "-------------epoch:2 begining---------------\n",
      "total_train_times: 800 total_loss: tensor(1.8278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 900 total_loss: tensor(1.9261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1000 total_loss: tensor(1.8976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1100 total_loss: tensor(1.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1200 total_loss: tensor(1.5436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1300 total_loss: tensor(1.5939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1400 total_loss: tensor(1.7978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1500 total_loss: tensor(1.5891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(277.1544, device='cuda:0')\n",
      "-------------epoch:3 begining---------------\n",
      "total_train_times: 1600 total_loss: tensor(1.6314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1700 total_loss: tensor(1.6578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1800 total_loss: tensor(1.5804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 1900 total_loss: tensor(1.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2000 total_loss: tensor(1.5311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2100 total_loss: tensor(1.5057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2200 total_loss: tensor(1.8183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2300 total_loss: tensor(1.5391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(249.5698, device='cuda:0')\n",
      "-------------epoch:4 begining---------------\n",
      "total_train_times: 2400 total_loss: tensor(1.6595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2500 total_loss: tensor(2.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2600 total_loss: tensor(1.4744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2700 total_loss: tensor(1.8361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2800 total_loss: tensor(1.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 2900 total_loss: tensor(1.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3000 total_loss: tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3100 total_loss: tensor(1.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(237.9063, device='cuda:0')\n",
      "-------------epoch:5 begining---------------\n",
      "total_train_times: 3200 total_loss: tensor(1.5032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3300 total_loss: tensor(1.6845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3400 total_loss: tensor(1.6545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3500 total_loss: tensor(1.4249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3600 total_loss: tensor(1.4446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3700 total_loss: tensor(1.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3800 total_loss: tensor(1.2378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 3900 total_loss: tensor(1.3409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(239.7976, device='cuda:0')\n",
      "-------------epoch:6 begining---------------\n",
      "total_train_times: 4000 total_loss: tensor(1.3824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4100 total_loss: tensor(1.4331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4200 total_loss: tensor(1.3818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4300 total_loss: tensor(1.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4400 total_loss: tensor(1.4188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4500 total_loss: tensor(1.4515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4600 total_loss: tensor(1.3758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(278.3901, device='cuda:0')\n",
      "-------------epoch:7 begining---------------\n",
      "total_train_times: 4700 total_loss: tensor(1.3092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4800 total_loss: tensor(1.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 4900 total_loss: tensor(1.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5000 total_loss: tensor(1.5955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5100 total_loss: tensor(1.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5200 total_loss: tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5300 total_loss: tensor(1.2783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5400 total_loss: tensor(1.2557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(205.9724, device='cuda:0')\n",
      "-------------epoch:8 begining---------------\n",
      "total_train_times: 5500 total_loss: tensor(1.2992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5600 total_loss: tensor(1.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5700 total_loss: tensor(1.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5800 total_loss: tensor(1.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 5900 total_loss: tensor(1.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6000 total_loss: tensor(1.4868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6100 total_loss: tensor(1.2685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6200 total_loss: tensor(1.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_loss: tensor(204.9191, device='cuda:0')\n",
      "-------------epoch:9 begining---------------\n",
      "total_train_times: 6300 total_loss: tensor(1.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6400 total_loss: tensor(0.9973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6500 total_loss: tensor(1.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6600 total_loss: tensor(1.1557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6700 total_loss: tensor(1.1949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6800 total_loss: tensor(1.0604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total_train_times: 6900 total_loss: tensor(1.4753, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,epoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-------------epoch:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m begining---------------\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_data_loader:\n\u001B[0;32m      4\u001B[0m         imgs,labels\u001B[38;5;241m=\u001B[39mdata\n\u001B[0;32m      5\u001B[0m         imgs\u001B[38;5;241m=\u001B[39mimgs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 732\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    736\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    738\u001B[0m ):\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    787\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 788\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    789\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    790\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    172\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mview(pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m1\u001B[39m], pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m0\u001B[39m], F_pil\u001B[38;5;241m.\u001B[39mget_image_num_channels(pic))\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# put it from HWC to CHW format\u001B[39;00m\n\u001B[1;32m--> 174\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mdefault_float_dtype)\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T09:32:47.464661500Z",
     "start_time": "2025-10-25T08:27:58.280975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5414b223e5ae669f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
