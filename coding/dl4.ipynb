{
 "cells": [
  {
   "cell_type": "code",
   "id": "0a9473b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.692072Z",
     "start_time": "2025-10-25T07:18:51.676200Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import Conv2d,MaxPool2d,Flatten,Linear"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "5bfa609c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.736592Z",
     "start_time": "2025-10-25T07:18:51.720478Z"
    }
   },
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=Conv2d(3,32,5,padding=2)\n",
    "        self.maxPool1=MaxPool2d(2)\n",
    "        self.conv2=Conv2d(32,32,5,padding=2)\n",
    "        self.maxPool2=MaxPool2d(2)\n",
    "        self.conv3=Conv2d(32,64,5,padding=2)\n",
    "        self.maxPool3=MaxPool2d(2)\n",
    "        self.flatten=Flatten()\n",
    "        self.linear1=Linear(1024,64) \n",
    "        self.linear2=Linear(64,10)\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.maxPool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.maxPool2(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.maxPool3(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        return x\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ab0067de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.752465Z",
     "start_time": "2025-10-25T07:18:51.742638Z"
    }
   },
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            Conv2d(3,32,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32,32,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32,64,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Flatten(),\n",
    "            Linear(1024,64) ,\n",
    "            Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "82c8f1b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.784249Z",
     "start_time": "2025-10-25T07:18:51.752465Z"
    }
   },
   "source": [
    "model=myModel()\n",
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "443f2c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.817129Z",
     "start_time": "2025-10-25T07:18:51.801490Z"
    }
   },
   "source": [
    "import torch\n",
    "tmp=torch.randn((64,3,32,32))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "4a97b5c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.872878Z",
     "start_time": "2025-10-25T07:18:51.817129Z"
    }
   },
   "source": [
    "model(tmp)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0549,  0.2123, -0.0499,  0.0381,  0.0337, -0.0554, -0.1054,  0.0345,\n",
       "          0.0911,  0.0696],\n",
       "        [ 0.0451,  0.2037, -0.0960,  0.0123,  0.0083, -0.0605, -0.0846,  0.0097,\n",
       "          0.0885,  0.1299],\n",
       "        [ 0.0397,  0.1851, -0.0701,  0.0456,  0.0248, -0.0528, -0.1014,  0.0464,\n",
       "          0.0780,  0.1356],\n",
       "        [ 0.0318,  0.1634, -0.0900,  0.0162,  0.0090, -0.0640, -0.1102,  0.0535,\n",
       "          0.0834,  0.1132],\n",
       "        [ 0.0499,  0.1821, -0.0652,  0.0426,  0.0323, -0.0794, -0.0880,  0.0043,\n",
       "          0.1257,  0.0964],\n",
       "        [ 0.0302,  0.1792, -0.0882,  0.0342,  0.0040, -0.0823, -0.0769,  0.0228,\n",
       "          0.1112,  0.0718],\n",
       "        [ 0.0570,  0.1761, -0.0969,  0.0129, -0.0009, -0.0658, -0.0510,  0.0320,\n",
       "          0.0877,  0.0855],\n",
       "        [ 0.0324,  0.1855, -0.0334,  0.0307,  0.0564, -0.0621, -0.1040,  0.0267,\n",
       "          0.0925,  0.0958],\n",
       "        [ 0.0516,  0.1951, -0.1070,  0.0612,  0.0097, -0.0782, -0.0866,  0.0151,\n",
       "          0.0997,  0.1313],\n",
       "        [ 0.0623,  0.1758, -0.0794, -0.0054, -0.0084, -0.0747, -0.0828,  0.0095,\n",
       "          0.1098,  0.0713],\n",
       "        [ 0.0750,  0.1737, -0.1024,  0.0264,  0.0203, -0.0646, -0.0918,  0.0080,\n",
       "          0.0919,  0.0920],\n",
       "        [ 0.0441,  0.1823, -0.1002,  0.0177,  0.0067, -0.0764, -0.0932,  0.0519,\n",
       "          0.0305,  0.1258],\n",
       "        [ 0.0229,  0.1419, -0.0864,  0.0319,  0.0218, -0.0524, -0.0770,  0.0290,\n",
       "          0.1135,  0.1163],\n",
       "        [ 0.0848,  0.1698, -0.0836,  0.0405,  0.0464, -0.0422, -0.0756,  0.0212,\n",
       "          0.1054,  0.0936],\n",
       "        [ 0.0621,  0.1713, -0.0897,  0.0005,  0.0025, -0.0483, -0.0794,  0.0201,\n",
       "          0.1079,  0.1040],\n",
       "        [ 0.0367,  0.2031, -0.0671,  0.0505,  0.0222, -0.0451, -0.0804, -0.0052,\n",
       "          0.0613,  0.0902],\n",
       "        [ 0.0365,  0.1842, -0.0983,  0.0420,  0.0168, -0.0420, -0.0682,  0.0264,\n",
       "          0.0817,  0.1031],\n",
       "        [ 0.0542,  0.1582, -0.0768, -0.0207,  0.0120, -0.0560, -0.0773,  0.0520,\n",
       "          0.0922,  0.1272],\n",
       "        [ 0.0414,  0.1903, -0.0643,  0.0634,  0.0100, -0.0593, -0.1339,  0.0235,\n",
       "          0.1034,  0.1153],\n",
       "        [ 0.0653,  0.1964, -0.0505,  0.0165,  0.0152, -0.0374, -0.0896,  0.0491,\n",
       "          0.0602,  0.1579],\n",
       "        [ 0.0320,  0.1996, -0.0882,  0.0444,  0.0301, -0.0369, -0.0800,  0.0008,\n",
       "          0.0555,  0.0711],\n",
       "        [ 0.0045,  0.1771, -0.1079,  0.0225,  0.0115, -0.0527, -0.1227,  0.0272,\n",
       "          0.0811,  0.1182],\n",
       "        [ 0.0575,  0.1744, -0.0478,  0.0478,  0.0521, -0.0290, -0.1036,  0.0156,\n",
       "          0.0698,  0.0919],\n",
       "        [ 0.0603,  0.1520, -0.0719,  0.0065,  0.0460, -0.0191, -0.0628,  0.0548,\n",
       "          0.0651,  0.1132],\n",
       "        [ 0.0325,  0.1996, -0.0877,  0.0320, -0.0055, -0.0563, -0.1080,  0.0037,\n",
       "          0.0913,  0.0777],\n",
       "        [ 0.0261,  0.1661, -0.0769,  0.0089,  0.0403, -0.0582, -0.0775,  0.0386,\n",
       "          0.0843,  0.1187],\n",
       "        [ 0.0722,  0.1855, -0.0827,  0.0486,  0.0189, -0.0996, -0.1206, -0.0068,\n",
       "          0.0791,  0.1094],\n",
       "        [ 0.0401,  0.1899, -0.0908,  0.0703, -0.0186, -0.0529, -0.1035,  0.0313,\n",
       "          0.0918,  0.1515],\n",
       "        [ 0.0585,  0.1502, -0.0826,  0.0451,  0.0027, -0.0346, -0.0531,  0.0286,\n",
       "          0.0976,  0.0997],\n",
       "        [ 0.0419,  0.1847, -0.0597,  0.0080,  0.0446, -0.0293, -0.0756,  0.0367,\n",
       "          0.0930,  0.0832],\n",
       "        [ 0.0507,  0.1825, -0.0865,  0.0359,  0.0405, -0.0656, -0.0843,  0.0320,\n",
       "          0.0801,  0.0925],\n",
       "        [ 0.0498,  0.1668, -0.0546,  0.0480,  0.0471, -0.0321, -0.0972,  0.0289,\n",
       "          0.0729,  0.0975],\n",
       "        [ 0.0266,  0.1637, -0.0747,  0.0281,  0.0117, -0.0261, -0.0882,  0.0391,\n",
       "          0.0837,  0.0592],\n",
       "        [ 0.0427,  0.2278, -0.1081,  0.0122,  0.0280, -0.0457, -0.0668,  0.0626,\n",
       "          0.0730,  0.1072],\n",
       "        [ 0.0187,  0.1814, -0.0980,  0.0160, -0.0125, -0.0674, -0.0946,  0.0553,\n",
       "          0.0850,  0.1266],\n",
       "        [ 0.0545,  0.1634, -0.1033,  0.0401, -0.0037, -0.0558, -0.0857,  0.0409,\n",
       "          0.1123,  0.1226],\n",
       "        [ 0.0255,  0.1787, -0.0834,  0.0141,  0.0419, -0.0739, -0.0735,  0.0248,\n",
       "          0.0939,  0.0613],\n",
       "        [ 0.0532,  0.1986, -0.1077,  0.0470,  0.0112, -0.0203, -0.0794,  0.0236,\n",
       "          0.0628,  0.0927],\n",
       "        [ 0.0350,  0.1673, -0.0751,  0.0320,  0.0202, -0.0534, -0.0860,  0.0460,\n",
       "          0.1099,  0.0784],\n",
       "        [ 0.0523,  0.2092, -0.0937,  0.0395,  0.0447, -0.0768, -0.0981,  0.0431,\n",
       "          0.0768,  0.0866],\n",
       "        [ 0.0491,  0.1695, -0.0711,  0.0215,  0.0260, -0.0457, -0.0881,  0.0305,\n",
       "          0.0964,  0.1235],\n",
       "        [ 0.0584,  0.1780, -0.0671,  0.0177,  0.0204, -0.0462, -0.1172,  0.0641,\n",
       "          0.0788,  0.1510],\n",
       "        [ 0.0449,  0.1400, -0.0867,  0.0902,  0.0268, -0.0201, -0.0703,  0.0280,\n",
       "          0.0608,  0.1035],\n",
       "        [ 0.0388,  0.2057, -0.0719,  0.0501,  0.0252, -0.0616, -0.0936,  0.0370,\n",
       "          0.0854,  0.0788],\n",
       "        [ 0.0360,  0.1553, -0.0597,  0.0039,  0.0052, -0.0618, -0.0973,  0.0752,\n",
       "          0.0967,  0.1352],\n",
       "        [ 0.0258,  0.2054, -0.0939,  0.0322,  0.0204, -0.0650, -0.1170,  0.0152,\n",
       "          0.0896,  0.0702],\n",
       "        [ 0.0422,  0.1723, -0.0866,  0.0215,  0.0516, -0.0580, -0.0661,  0.0250,\n",
       "          0.0819,  0.1062],\n",
       "        [ 0.0692,  0.1558, -0.0784,  0.0257,  0.0463, -0.0373, -0.0906,  0.0113,\n",
       "          0.0824,  0.0636],\n",
       "        [ 0.0557,  0.1971, -0.0702,  0.0140,  0.0348, -0.0678, -0.0991,  0.0419,\n",
       "          0.0580,  0.1380],\n",
       "        [ 0.0458,  0.1751, -0.0847,  0.0620,  0.0131, -0.0685, -0.1037, -0.0107,\n",
       "          0.1424,  0.0843],\n",
       "        [ 0.0438,  0.1815, -0.0811,  0.0669,  0.0127, -0.0830, -0.1308,  0.0200,\n",
       "          0.0940,  0.1013],\n",
       "        [ 0.0615,  0.1700, -0.0467,  0.0450,  0.0004, -0.0655, -0.0608,  0.0350,\n",
       "          0.0953,  0.0746],\n",
       "        [ 0.0504,  0.1484, -0.0759,  0.0078,  0.0153, -0.0622, -0.0847,  0.0569,\n",
       "          0.0996,  0.1132],\n",
       "        [ 0.0454,  0.2070, -0.0954,  0.0219,  0.0425, -0.0693, -0.0808,  0.0208,\n",
       "          0.0843,  0.1499],\n",
       "        [ 0.0327,  0.1607, -0.0918,  0.0458,  0.0136, -0.0464, -0.0918,  0.0696,\n",
       "          0.0895,  0.1261],\n",
       "        [ 0.0417,  0.2275, -0.0971,  0.0174,  0.0262, -0.0318, -0.0894,  0.0515,\n",
       "          0.0857,  0.1339],\n",
       "        [ 0.0635,  0.1820, -0.1073,  0.0482,  0.0363, -0.0535, -0.0697,  0.0477,\n",
       "          0.1006,  0.1174],\n",
       "        [ 0.0558,  0.1468, -0.0549,  0.0335,  0.0355, -0.0293, -0.0961,  0.0246,\n",
       "          0.0673,  0.1159],\n",
       "        [ 0.0632,  0.1752, -0.0707,  0.0554,  0.0319, -0.0418, -0.1008,  0.0432,\n",
       "          0.0738,  0.1294],\n",
       "        [ 0.0559,  0.1833, -0.0821,  0.0257, -0.0120, -0.0477, -0.1179,  0.0120,\n",
       "          0.0786,  0.1343],\n",
       "        [ 0.0134,  0.1634, -0.0814,  0.0104,  0.0096, -0.0505, -0.0984,  0.0385,\n",
       "          0.1047,  0.0853],\n",
       "        [ 0.0818,  0.1722, -0.0735,  0.0435,  0.0261, -0.0572, -0.0805,  0.0295,\n",
       "          0.1082,  0.0921],\n",
       "        [ 0.0501,  0.1721, -0.0911,  0.0052,  0.0148, -0.0500, -0.0924,  0.0208,\n",
       "          0.1085,  0.0918],\n",
       "        [ 0.0247,  0.2165, -0.0972,  0.0290,  0.0482, -0.0678, -0.0975,  0.0585,\n",
       "          0.0837,  0.1219]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "39fc78dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:51.904817Z",
     "start_time": "2025-10-25T07:18:51.897286Z"
    }
   },
   "source": [
    "fla=Flatten()\n",
    "tmp=torch.ones((64,3,32,32))\n",
    "fla(tmp).shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3072])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "91df696c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:52.478932Z",
     "start_time": "2025-10-25T07:18:51.910842Z"
    }
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer=SummaryWriter('log4')\n",
    "writer.add_graph(model,tmp)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "57e28a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:18:57.098330Z",
     "start_time": "2025-10-25T07:18:52.484650Z"
    }
   },
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "datas=datasets.CIFAR10(root='./datasets',transform=transforms.ToTensor(),train=True,download=True)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1e1db23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:19:28.812477Z",
     "start_time": "2025-10-25T07:19:27.987318Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader=DataLoader(datas,batch_size=32)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "for data in loader:\n",
    "    imgs,labels=data\n",
    "    out=model(imgs)    \n",
    "    print(out.shape,labels.shape)\n",
    "    res_loss=loss(out,labels)\n",
    "    res_loss.backward()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n",
      "torch.Size([32, 10]) torch.Size([32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(out\u001B[38;5;241m.\u001B[39mshape,labels\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      9\u001B[0m res_loss\u001B[38;5;241m=\u001B[39mloss(out,labels)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mres_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\_tensor.py:625\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    617\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    618\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    623\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    624\u001B[0m     )\n\u001B[1;32m--> 625\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    839\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    840\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 841\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    842\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    843\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    844\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
